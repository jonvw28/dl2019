# Deep learning 2019 (half) course

Lectures to be held in MR15, Faculty of Mathematics, Fridays 1-3pm.


### Instructors

Stephen J Eglen (Maths), Martin Johnson (AstraZeneca) and Adam
Corrigan (AstraZeneca).


### Timetable (subject to revision)

1. Feb 22.  Introduction: motivating examples.  History.  From
   perceptrons to multilayer perceptrons.  The importance of features.
   Practical matters.  (SJE)  [Lecture notes](dl-1.pdf)


2. Mar 01.  Learning in networks.  (Error functions, Back propagation,
   automatic differentiation, gradient-descent methods).  First
   examples at classification.  Hyper-parameters. (SJE)
   [Lecture notes](dl-2.pdf)
   [mnist.Rmd](mnist/mnist_bp.Rmd)
   [mnist.html](https://raw.githack.com/sje30/dl2019/master/mnist/mnist_bp.html)
   [backprop derivation](backprop.pdf)
   
3. Mar 08.  Image classification and segmentation.  Convolutional
   neural networks. Autoencoders. Applications. (SJE and AC).
   [Lecture notes/1](dl-3.pdf)
   [Lecture notes/2](Corrigan-CCBI-small.pptx)
   
4. Mar 15.  Temporal processing.  Recurrent neural networks (RNN) and
   Long-short-term memories (LSTM).  Applications.  (SJE and MJ).
   [Lecture notes/1](dl-4.pdf)
   
### Text for practical work

Practical work (for the assignment) will be set following the guidance
in here.
[Deep learning with R](https://www.manning.com/books/deep-learning-with-r)


### Reading

Key referencs will be made available in this [Paperpile folder](https://paperpile.com/shared/pb4w0p)





